# Statistics-and-Machine-Learning

#### All the laboratory work I did for the master studies in Statistics and Machine Learning can be found In this repository.

* ## [Machine Learning](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Machine%20Learning)
 
    The course introduces main principles and methods of machine learning in R which are necessary for analysis of large or complex         data. It presents machine learning mainly from a probabilistic framework, but successful non-probabilistic methods are also             covered. 
    
    This course covers:
     * Basic concepts in machine learning. Software. Regression, regularization and model selection.
     
     * Classification methods. Dimensionality reduction and uncertainty estimation.
     
     * Kernel methods and support vector machines. Neural networks and deep learning.
     
     * Ensemble methods and mixture models. Online Learning.
     
     * Splines and additive models. High-dimensional problems.
     
 * ## [Advanced Machine Learning](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Advanced%20Machine%20Learning)
  
    The course covers advanced topics in machine learning, primarily from Bayesian perspective in R.The course includes laboratory     works   in which students get a practical experience of data analysis. 
  A major part of the course is devoted to  Graphical models, such as
  
   * Hidden Markov Models.
   
   * Bayesian networks.
   
   * Markov random fields and other methods. 
 
 * ## [Advanced R programming](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Advanced%20R%20Programming)
 
    The course is devoted to studying the programming language R, including its standard and more advanced tools. 
    
    It covers concepts such as:
      * Reading data from file and from the internet.
      
      * Data structures, functions and objects.
      
      * Debugging and object-oriented programming.
      
      * Performance enhancement, parallel programming and many other advanced concepts.
 
* ## [Introduction to Python](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Introduction%20to%20Python)

    The course covers Python basics and more advanced concepts such as:
    
     * Data structures.
      
     * Functions and functional programming.
     
     * Classes and object oriented programming.
     
     * Standard library and debbuging. 
    
* ## [Neural Networks and Learning systems](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Neural%20Networks%20and%20Learing%20Systems)

    The course aims to explain the differences between particular learning paradigms, selecting an appropriate method for solving a given problem and implement the method. The laboratory work has been done in Matlab.

    The course includes Supervised Learning, Unsupervised Learning and Reinforcement Learning.
    
     * Supervised Learning: neural networks, linear discriminants, support vector machines, ensemble learning, boosting, deep learning.
      
     * Unsupervised Learning: patterns in high-dimensional data, dimensionality reduction, clustering, principal component analysis,             linear discriminant analysis.
      
     * Reinforcement Learning: TD-learning, Q-learningIn.
     
* ## [Advanced Data mining](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Advanced%20Data%20Mining)
    
    All labs at this course are done with Weka v3.6.12 and reports focus on comparison of algorithms and choosing parameter. Additionally,       Apriori, FP-grow algorithms; K-Means, K-medoids, PAM clustering, CLARA, CLARANS, BIRCH algorithms are being studied and run step by step.

    This course covers the following content:
    
     * Clustering | Partitioning Methods: K-Means, K-Medoids, PAM, CLARA, CLARANS.
      
     * Clustering | Hierarchical Methods: AGNES, DIANA; BIRCH, ROCK, CHAMELEON.
      
     * Clustering | Density-Based Methods: DBSCAN, OPTICS, Denclue.
      
     * Association Analysis: Apriori algorithm, FP-grow Algorithm, Monotone/Antimonotone Constraints.
     
* ## [Text Mining](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/text_Mining)

    The goal of this course is to introduce the main tools of the text mining trade such as:
    
    * Information retrieval
    
    * Natural language processing
    
    * Topel modelling
    
    * Information extraction
     
* ## [Computational Statistics](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Computational%20Statistics)
  
    The course includes computational applications of statistics in R and covers as main topics:
    
     * Computer arithmetics.
      
     * Optimization.
      
     * Random number generation,
      
     * Monte Carlo methods, MCMC,
      
     * Numerical model selection and hyphothesis testing,
      
     * EM algorithm and stochastic optimization (specifically genetic algorithms).
      
 * ## [Big Data Analytics](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Big%20Data%20Analytics)
    
    The programming language of this course is Python and database technologies are Spark and SparkSQL. The structure of the big data,       which is used in labs, can be found in the repository.This course covers the  following topics:
    
    * Introduction to Big Data: concept and tools.
    
    * Parallel computing.
    
    * Databases for Big Data (NoSql, HDFS).
    
    * Querying for Big Data (Spark, SparkSQL).
    
    * Resource management in a cluster environment.
    
    * Parallelizing computations for Big Data. MapReduce concept.
    
    * Machine Learning for Big Data.

* ## [Bayesian Learning](https://github.com/stasinak/Statistics-and-Machine-Learning/tree/master/Bayesian%20Learning)

    The course aims to give a solid introduction to the Bayesian approach to statistical inference in R, with a view towards               applications in machine learning. 

    The course covers the  4 modules below:
    
     * Bayesics: Basic concepts about likelihood, priors, (one|multi)-parameter models, marginalization.
     
     * Bayesian Regression and Classification.
     
     * More advanced models, MCMC and Variational Bayes.
     
     * Model Inference and Variable Selection.



* ## Probability Theory

  The course provides a theoretical foundation of models and methods based on the concept of probability. All the assignments are written in paper. The course comprises:
  
  *  Probability distributions for univariate and multivariate random variables.
 
  *  Expected value, variance, moments.

  * Joint distribution, conditional distribution, independence.

  * The elements of the Bayesian approach.

  * Transforms.

  * Order statistics.

  *  Multivariate normal distribution and its properties.

  * Types of convergence and convergence theorems.

* ## Decision Theory

  The course content gives a foundamental knowledge in Bayesian Inference and Decision Theory. The assignments are written in paper. 
  The contexts which the course covers are the following :
  
    * The subjective interpretation of probabilities.
    
    * Probabilistic reasoning and likelihood theory. 
    
    * Bayesian hypothesis evaluation.
    
    * Decision theoretic elements.
    
    * Utility and loss functions.
    
    * Graphical modelling as a tool for decision making.
    
    * Sequential analysis.

* ## Statistical Methods 

  The course provides a theoretical basis of statistical concepts and methods that are required for qualified work and research in statistics. The course contents cover major concepts and methods from different statistical branches such as: 
  
  * Probability theory.
  
  * Statistical inference.
  
  * Stochastic processes.
  
  * Bayesian theory.
  
  * Regression analysis and sampling.

